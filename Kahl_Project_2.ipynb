{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load your data, including testing/training split from Project 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "employee_data = pd.read_csv(\"Employee_attrition.csv\")\n",
    "employee_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  DailyRate              Department  DistanceFromHome  Education  \\\n",
      "0      41       1102                   Sales                 1          2   \n",
      "1      49        279  Research & Development                 8          1   \n",
      "2      37       1373  Research & Development                 2          2   \n",
      "3      33       1392  Research & Development                 3          4   \n",
      "4      27        591  Research & Development                 2          1   \n",
      "...   ...        ...                     ...               ...        ...   \n",
      "1465   36        884  Research & Development                23          2   \n",
      "1466   39        613  Research & Development                 6          1   \n",
      "1467   27        155  Research & Development                 4          3   \n",
      "1468   49       1023                   Sales                 2          3   \n",
      "1469   34        628  Research & Development                 8          3   \n",
      "\n",
      "      EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  \\\n",
      "0                           2  Female          94               3         2   \n",
      "1                           3    Male          61               2         2   \n",
      "2                           4    Male          92               2         1   \n",
      "3                           4  Female          56               3         1   \n",
      "4                           1    Male          40               3         1   \n",
      "...                       ...     ...         ...             ...       ...   \n",
      "1465                        3    Male          41               4         2   \n",
      "1466                        4    Male          42               2         3   \n",
      "1467                        2    Male          87               4         2   \n",
      "1468                        4    Male          63               2         2   \n",
      "1469                        2    Male          82               4         2   \n",
      "\n",
      "      ... PerformanceRating  RelationshipSatisfaction StandardHours  \\\n",
      "0     ...                 3                         1            80   \n",
      "1     ...                 4                         4            80   \n",
      "2     ...                 3                         2            80   \n",
      "3     ...                 3                         3            80   \n",
      "4     ...                 3                         4            80   \n",
      "...   ...               ...                       ...           ...   \n",
      "1465  ...                 3                         3            80   \n",
      "1466  ...                 3                         1            80   \n",
      "1467  ...                 4                         2            80   \n",
      "1468  ...                 3                         4            80   \n",
      "1469  ...                 3                         1            80   \n",
      "\n",
      "      TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  \\\n",
      "0                     8                      0                1   \n",
      "1                    10                      3                3   \n",
      "2                     7                      3                3   \n",
      "3                     8                      3                3   \n",
      "4                     6                      3                3   \n",
      "...                 ...                    ...              ...   \n",
      "1465                 17                      3                3   \n",
      "1466                  9                      5                3   \n",
      "1467                  6                      0                3   \n",
      "1468                 17                      3                2   \n",
      "1469                  6                      3                4   \n",
      "\n",
      "      YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
      "0                  6                   4                        0   \n",
      "1                 10                   7                        1   \n",
      "2                  0                   0                        0   \n",
      "3                  8                   7                        3   \n",
      "4                  2                   2                        2   \n",
      "...              ...                 ...                      ...   \n",
      "1465               5                   2                        0   \n",
      "1466               7                   7                        1   \n",
      "1467               6                   2                        0   \n",
      "1468               9                   6                        0   \n",
      "1469               4                   3                        1   \n",
      "\n",
      "      YearsWithCurrManager  \n",
      "0                        5  \n",
      "1                        7  \n",
      "2                        0  \n",
      "3                        0  \n",
      "4                        2  \n",
      "...                    ...  \n",
      "1465                     3  \n",
      "1466                     7  \n",
      "1467                     3  \n",
      "1468                     8  \n",
      "1469                     2  \n",
      "\n",
      "[1470 rows x 26 columns]\n",
      "X.shape: (1470, 26)  y.shape: (1470,)\n"
     ]
    }
   ],
   "source": [
    "X = employee_data.drop(['Attrition', 'Over18', 'MonthlyRate','EducationField', 'BusinessTravel', 'EmployeeCount', 'EmployeeNumber', 'OverTime', 'StockOptionLevel'],axis=1)\n",
    "print(X)\n",
    "y = employee_data['Attrition'].values\n",
    "print(\"X.shape: {}  y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1102 entries, 944 to 684\n",
      "Data columns (total 26 columns):\n",
      "Age                         1102 non-null int64\n",
      "DailyRate                   1102 non-null int64\n",
      "Department                  1102 non-null object\n",
      "DistanceFromHome            1102 non-null int64\n",
      "Education                   1102 non-null int64\n",
      "EnvironmentSatisfaction     1102 non-null int64\n",
      "Gender                      1102 non-null object\n",
      "HourlyRate                  1102 non-null int64\n",
      "JobInvolvement              1102 non-null int64\n",
      "JobLevel                    1102 non-null int64\n",
      "JobRole                     1102 non-null object\n",
      "JobSatisfaction             1102 non-null int64\n",
      "MaritalStatus               1102 non-null object\n",
      "MonthlyIncome               1102 non-null int64\n",
      "NumCompaniesWorked          1102 non-null int64\n",
      "PercentSalaryHike           1102 non-null int64\n",
      "PerformanceRating           1102 non-null int64\n",
      "RelationshipSatisfaction    1102 non-null int64\n",
      "StandardHours               1102 non-null int64\n",
      "TotalWorkingYears           1102 non-null int64\n",
      "TrainingTimesLastYear       1102 non-null int64\n",
      "WorkLifeBalance             1102 non-null int64\n",
      "YearsAtCompany              1102 non-null int64\n",
      "YearsInCurrentRole          1102 non-null int64\n",
      "YearsSinceLastPromotion     1102 non-null int64\n",
      "YearsWithCurrManager        1102 non-null int64\n",
      "dtypes: int64(22), object(4)\n",
      "memory usage: 232.5+ KB\n",
      "['No' 'No' 'No' ... 'No' 'No' 'No']\n"
     ]
    }
   ],
   "source": [
    "X_train.info()\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: (If not already done in Project 1) Prepare your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "y_train = ordinal_encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "y_test = ordinal_encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[923 179]\n",
      "[[  0. 923.]\n",
      " [  1. 179.]]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: evaluate your target variable\n",
    "# evaluating the frequencies of yes and no for my target attribute of attrition \n",
    "unqine, commacounts = np.unique(y_train, return_counts=True) #np array for ordinal variable\n",
    "print(commacounts)\n",
    "frequencies = np.asarray((unqine, commacounts)).T # T is for transpose, so we an change rows to columns\n",
    "# 0 is no, 1 is yes\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Human Resources  Research & Development  Sales\n",
      "0                 0.0                     0.0    1.0\n",
      "1                 0.0                     1.0    0.0\n",
      "2                 0.0                     1.0    0.0\n",
      "3                 0.0                     1.0    0.0\n",
      "4                 0.0                     1.0    0.0\n",
      "...               ...                     ...    ...\n",
      "1465              0.0                     1.0    0.0\n",
      "1466              0.0                     1.0    0.0\n",
      "1467              0.0                     1.0    0.0\n",
      "1468              0.0                     0.0    1.0\n",
      "1469              0.0                     1.0    0.0\n",
      "\n",
      "[1470 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do the Encoding for the Labels of \"Type\" \n",
    "# finishing cleaning the data set for step 2\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "type_le = LabelEncoder()\n",
    "type_labels = type_le.fit_transform(X['Department'])\n",
    "X['Department_labels'] = type_labels\n",
    "type_creation = OneHotEncoder()\n",
    "label_feature_arr = type_creation.fit_transform(\n",
    "                              X[['Department_labels']]).toarray()\n",
    "gen_feature_labels = list(type_le.classes_)\n",
    "department_ohe = pd.DataFrame(label_feature_arr, \n",
    "                            columns=gen_feature_labels)\n",
    "print(department_ohe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Female  Male\n",
      "0        1.0   0.0\n",
      "1        0.0   1.0\n",
      "2        0.0   1.0\n",
      "3        1.0   0.0\n",
      "4        0.0   1.0\n",
      "...      ...   ...\n",
      "1465     0.0   1.0\n",
      "1466     0.0   1.0\n",
      "1467     0.0   1.0\n",
      "1468     0.0   1.0\n",
      "1469     0.0   1.0\n",
      "\n",
      "[1470 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do the Encoding for the Labels of \"Type\" \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "type_le = LabelEncoder()\n",
    "type_labels = type_le.fit_transform(X['Gender'])\n",
    "X['Gender_labels'] = type_labels\n",
    "type_creation = OneHotEncoder()\n",
    "label_feature_arr = type_creation.fit_transform(\n",
    "                              X[['Gender_labels']]).toarray()\n",
    "gen_feature_labels = list(type_le.classes_)\n",
    "gender_ohe = pd.DataFrame(label_feature_arr, \n",
    "                            columns=gen_feature_labels)\n",
    "print(gender_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Healthcare Representative  Human Resources  Laboratory Technician  \\\n",
      "0                           0.0              0.0                    0.0   \n",
      "1                           0.0              0.0                    0.0   \n",
      "2                           0.0              0.0                    1.0   \n",
      "3                           0.0              0.0                    0.0   \n",
      "4                           0.0              0.0                    1.0   \n",
      "...                         ...              ...                    ...   \n",
      "1465                        0.0              0.0                    1.0   \n",
      "1466                        1.0              0.0                    0.0   \n",
      "1467                        0.0              0.0                    0.0   \n",
      "1468                        0.0              0.0                    0.0   \n",
      "1469                        0.0              0.0                    1.0   \n",
      "\n",
      "      Manager  Manufacturing Director  Research Director  Research Scientist  \\\n",
      "0         0.0                     0.0                0.0                 0.0   \n",
      "1         0.0                     0.0                0.0                 1.0   \n",
      "2         0.0                     0.0                0.0                 0.0   \n",
      "3         0.0                     0.0                0.0                 1.0   \n",
      "4         0.0                     0.0                0.0                 0.0   \n",
      "...       ...                     ...                ...                 ...   \n",
      "1465      0.0                     0.0                0.0                 0.0   \n",
      "1466      0.0                     0.0                0.0                 0.0   \n",
      "1467      0.0                     1.0                0.0                 0.0   \n",
      "1468      0.0                     0.0                0.0                 0.0   \n",
      "1469      0.0                     0.0                0.0                 0.0   \n",
      "\n",
      "      Sales Executive  Sales Representative  \n",
      "0                 1.0                   0.0  \n",
      "1                 0.0                   0.0  \n",
      "2                 0.0                   0.0  \n",
      "3                 0.0                   0.0  \n",
      "4                 0.0                   0.0  \n",
      "...               ...                   ...  \n",
      "1465              0.0                   0.0  \n",
      "1466              0.0                   0.0  \n",
      "1467              0.0                   0.0  \n",
      "1468              1.0                   0.0  \n",
      "1469              0.0                   0.0  \n",
      "\n",
      "[1470 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do the Encoding for the Labels of \"Type\" \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "type_le = LabelEncoder()\n",
    "type_labels = type_le.fit_transform(X['JobRole'])\n",
    "X['JobRole'] = type_labels\n",
    "type_creation = OneHotEncoder()\n",
    "label_feature_arr = type_creation.fit_transform(\n",
    "                              X[['JobRole']]).toarray()\n",
    "gen_feature_labels = list(type_le.classes_)\n",
    "jobrole_ohe = pd.DataFrame(label_feature_arr, \n",
    "                            columns=gen_feature_labels)\n",
    "print(jobrole_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Divorced  Married  Single\n",
      "0          0.0      0.0     1.0\n",
      "1          0.0      1.0     0.0\n",
      "2          0.0      0.0     1.0\n",
      "3          0.0      1.0     0.0\n",
      "4          0.0      1.0     0.0\n",
      "...        ...      ...     ...\n",
      "1465       0.0      1.0     0.0\n",
      "1466       0.0      1.0     0.0\n",
      "1467       0.0      1.0     0.0\n",
      "1468       0.0      1.0     0.0\n",
      "1469       0.0      1.0     0.0\n",
      "\n",
      "[1470 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do the Encoding for the Labels of \"Type\" \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "type_le = LabelEncoder()\n",
    "type_labels = type_le.fit_transform(X['MaritalStatus'])\n",
    "X['MaritalStatus'] = type_labels\n",
    "type_creation = OneHotEncoder()\n",
    "label_feature_arr = type_creation.fit_transform(\n",
    "                              X[['MaritalStatus']]).toarray()\n",
    "gen_feature_labels = list(type_le.classes_)\n",
    "MaritalStatus_ohe = pd.DataFrame(label_feature_arr, \n",
    "                            columns=gen_feature_labels)\n",
    "print(MaritalStatus_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Human Resources  Research & Development  Sales  Female  Male  \\\n",
      "0                 0.0                     0.0    1.0     1.0   0.0   \n",
      "1                 0.0                     1.0    0.0     0.0   1.0   \n",
      "2                 0.0                     1.0    0.0     0.0   1.0   \n",
      "3                 0.0                     1.0    0.0     1.0   0.0   \n",
      "4                 0.0                     1.0    0.0     0.0   1.0   \n",
      "...               ...                     ...    ...     ...   ...   \n",
      "1465              0.0                     1.0    0.0     0.0   1.0   \n",
      "1466              0.0                     1.0    0.0     0.0   1.0   \n",
      "1467              0.0                     1.0    0.0     0.0   1.0   \n",
      "1468              0.0                     0.0    1.0     0.0   1.0   \n",
      "1469              0.0                     1.0    0.0     0.0   1.0   \n",
      "\n",
      "      Healthcare Representative  Human Resources  Laboratory Technician  \\\n",
      "0                           0.0              0.0                    0.0   \n",
      "1                           0.0              0.0                    0.0   \n",
      "2                           0.0              0.0                    1.0   \n",
      "3                           0.0              0.0                    0.0   \n",
      "4                           0.0              0.0                    1.0   \n",
      "...                         ...              ...                    ...   \n",
      "1465                        0.0              0.0                    1.0   \n",
      "1466                        1.0              0.0                    0.0   \n",
      "1467                        0.0              0.0                    0.0   \n",
      "1468                        0.0              0.0                    0.0   \n",
      "1469                        0.0              0.0                    1.0   \n",
      "\n",
      "      Manager  Manufacturing Director  Research Director  Research Scientist  \\\n",
      "0         0.0                     0.0                0.0                 0.0   \n",
      "1         0.0                     0.0                0.0                 1.0   \n",
      "2         0.0                     0.0                0.0                 0.0   \n",
      "3         0.0                     0.0                0.0                 1.0   \n",
      "4         0.0                     0.0                0.0                 0.0   \n",
      "...       ...                     ...                ...                 ...   \n",
      "1465      0.0                     0.0                0.0                 0.0   \n",
      "1466      0.0                     0.0                0.0                 0.0   \n",
      "1467      0.0                     1.0                0.0                 0.0   \n",
      "1468      0.0                     0.0                0.0                 0.0   \n",
      "1469      0.0                     0.0                0.0                 0.0   \n",
      "\n",
      "      Sales Executive  Sales Representative  Divorced  Married  Single  \n",
      "0                 1.0                   0.0       0.0      0.0     1.0  \n",
      "1                 0.0                   0.0       0.0      1.0     0.0  \n",
      "2                 0.0                   0.0       0.0      0.0     1.0  \n",
      "3                 0.0                   0.0       0.0      1.0     0.0  \n",
      "4                 0.0                   0.0       0.0      1.0     0.0  \n",
      "...               ...                   ...       ...      ...     ...  \n",
      "1465              0.0                   0.0       0.0      1.0     0.0  \n",
      "1466              0.0                   0.0       0.0      1.0     0.0  \n",
      "1467              0.0                   0.0       0.0      1.0     0.0  \n",
      "1468              1.0                   0.0       0.0      1.0     0.0  \n",
      "1469              0.0                   0.0       0.0      1.0     0.0  \n",
      "\n",
      "[1470 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "label_dataframes = pd.concat([department_ohe, gender_ohe, jobrole_ohe, MaritalStatus_ohe ], axis = 1)\n",
    "print(label_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  DailyRate  DistanceFromHome  Education  EnvironmentSatisfaction  \\\n",
      "0      41       1102                 1          2                        2   \n",
      "1      49        279                 8          1                        3   \n",
      "2      37       1373                 2          2                        4   \n",
      "3      33       1392                 3          4                        4   \n",
      "4      27        591                 2          1                        1   \n",
      "...   ...        ...               ...        ...                      ...   \n",
      "1465   36        884                23          2                        3   \n",
      "1466   39        613                 6          1                        4   \n",
      "1467   27        155                 4          3                        2   \n",
      "1468   49       1023                 2          3                        4   \n",
      "1469   34        628                 8          3                        2   \n",
      "\n",
      "      HourlyRate  JobInvolvement  JobLevel  JobSatisfaction  MonthlyIncome  \\\n",
      "0             94               3         2                4           5993   \n",
      "1             61               2         2                2           5130   \n",
      "2             92               2         1                3           2090   \n",
      "3             56               3         1                3           2909   \n",
      "4             40               3         1                2           3468   \n",
      "...          ...             ...       ...              ...            ...   \n",
      "1465          41               4         2                4           2571   \n",
      "1466          42               2         3                1           9991   \n",
      "1467          87               4         2                2           6142   \n",
      "1468          63               2         2                2           5390   \n",
      "1469          82               4         2                3           4404   \n",
      "\n",
      "      ...  StandardHours  TotalWorkingYears  TrainingTimesLastYear  \\\n",
      "0     ...             80                  8                      0   \n",
      "1     ...             80                 10                      3   \n",
      "2     ...             80                  7                      3   \n",
      "3     ...             80                  8                      3   \n",
      "4     ...             80                  6                      3   \n",
      "...   ...            ...                ...                    ...   \n",
      "1465  ...             80                 17                      3   \n",
      "1466  ...             80                  9                      5   \n",
      "1467  ...             80                  6                      0   \n",
      "1468  ...             80                 17                      3   \n",
      "1469  ...             80                  6                      3   \n",
      "\n",
      "      WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
      "0                   1               6                   4   \n",
      "1                   3              10                   7   \n",
      "2                   3               0                   0   \n",
      "3                   3               8                   7   \n",
      "4                   3               2                   2   \n",
      "...               ...             ...                 ...   \n",
      "1465                3               5                   2   \n",
      "1466                3               7                   7   \n",
      "1467                3               6                   2   \n",
      "1468                2               9                   6   \n",
      "1469                4               4                   3   \n",
      "\n",
      "      YearsSinceLastPromotion  YearsWithCurrManager  Department_labels  \\\n",
      "0                           0                     5                  2   \n",
      "1                           1                     7                  1   \n",
      "2                           0                     0                  1   \n",
      "3                           3                     0                  1   \n",
      "4                           2                     2                  1   \n",
      "...                       ...                   ...                ...   \n",
      "1465                        0                     3                  1   \n",
      "1466                        1                     7                  1   \n",
      "1467                        0                     3                  1   \n",
      "1468                        0                     8                  2   \n",
      "1469                        1                     2                  1   \n",
      "\n",
      "      Gender_labels  \n",
      "0                 0  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 0  \n",
      "4                 1  \n",
      "...             ...  \n",
      "1465              1  \n",
      "1466              1  \n",
      "1467              1  \n",
      "1468              1  \n",
      "1469              1  \n",
      "\n",
      "[1470 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(['JobRole', 'Gender', 'Department', 'MaritalStatus' ],axis=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "# running this again with the change in categorical variables -- getting an error for KNN's\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mglearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26e192bcac8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4 Step 4: Selected two of the following supervised learning algorithms, \n",
    "#ideally one from the first half of the list and one from the second half of the list, I did 3 to experiment\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors,metric='manhattan')\n",
    "    knn.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(knn.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(knn.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn score: 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "# k = 4 since that was the example\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"knn score: {}\".format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn score: 0.8460884353741497\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "# k = 4 since that was the example\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"knn score: {}\".format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores:\n",
      "[0.81447964 0.83710407 0.85067873 0.82727273 0.81278539]\n",
      "cv_scores mean:\n",
      "0.828464111767899\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a\n",
    "# Now, running a cross-val to get a validation set. This will help determine which KNN I should use\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "#5-fold cross validation\n",
    "cv_scores = cross_val_score(knn_cv, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"cv_scores:\\n{}\".format(cv_scores))\n",
    "print(\"cv_scores mean:\\n{}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# grid search to see best parameters to use\n",
    "\n",
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "#dictionary of all values of k\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 25)}\n",
    "\n",
    "#grid search on all values of k in dictionary\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
       "                         'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24]),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "#dictionary of all values of k\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 25),\n",
    "             \"metric\": [\"manhattan\", \"minkowski\", \"euclidean\"],\n",
    "             \"weights\": [\"uniform\", \"distance\"]}\n",
    "# i want to see which parameters work best, so used above so I can tell which kind of metrics and weights \n",
    "\n",
    "#grid search on all values of k in dictionary\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best performing k (on training set)\n",
    "#also bset metric, and weights, which is uniform \n",
    "knn_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8393829401088929"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy of best performing k\n",
    "knn_gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[310   0]\n",
      " [ 58   0]]\n"
     ]
    }
   ],
   "source": [
    "knn20 = KNeighborsClassifier(n_neighbors=20)\n",
    "knn20.fit(X_train, y_train)\n",
    "# using 20 neighbors \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, knn20.predict(X_test))\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[306   4]\n",
      " [ 57   1]]\n"
     ]
    }
   ],
   "source": [
    "knn10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn10.fit(X_train, y_train)\n",
    "\n",
    "# running the confusion matrix again to see what it would look like with 10 neighbors \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, knn10.predict(X_test))\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.84      0.99      0.91       310\n",
      "          No       0.20      0.02      0.03        58\n",
      "\n",
      "    accuracy                           0.83       368\n",
      "   macro avg       0.52      0.50      0.47       368\n",
      "weighted avg       0.74      0.83      0.77       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: For each of your selected models\n",
    "\n",
    "#Run with the default parameters using cross-validation\n",
    "#Calculate precision, recall, and F1 for classification\n",
    "#Calculate r2, RMSE, and MAE for regression\n",
    "#Where possible adjust 2-3 parameters for each model\n",
    "#Report evaluation metrics for the best and worst-performing parameter settings\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, knn10.predict(X_test),\n",
    "                             target_names=[\"Yes\", \"No\"]))\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.84      1.00      0.91       310\n",
      "          No       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.84       368\n",
      "   macro avg       0.42      0.50      0.46       368\n",
      "weighted avg       0.71      0.84      0.77       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test with 20 \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, knn20.predict(X_test),\n",
    "                             target_names=[\"Yes\", \"No\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 but with SVC this time for a more complex model \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "# radial basis function kernel\n",
    "svmRBF1 = SVC(kernel='rbf', C=10, gamma=0.1).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svmRBF1.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svmRBF1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "# no kernal, it would not run with poly\n",
    "svmPoly1 = SVC(C=10).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svmPoly1.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svmPoly1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "# no kernal, it would not run with poly, this onehas a bigger C. the following cells just test out different C's and gamma's\n",
    "# before the grid search\n",
    "svmPoly1 = SVC(C=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svmPoly1.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svmPoly1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.84\n",
      "Accuracy on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# constrained model (low C and low gamma)\n",
    "svmRBF2 = SVC(kernel='rbf', C=0.1).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svmRBF2.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svmRBF2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# constrained model (low C and low gamma)\n",
    "svmRBF3 = SVC(kernel='rbf', C=1000, gamma=10).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svmRBF3.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svmRBF3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "svmRBFgrid = SVC(kernel='rbf', C=1, gamma=0.1).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svmRBFgrid.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svmRBFgrid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#estimator.get_params().keys()\n",
    "\n",
    "#estimator.get_params().keys()\n",
    "#param_grid\n",
    "# param_grid = {\"n_neighbors\": np.arange(1, 25),\n",
    "             #\"metric\": [\"manhattan\", \"minkowski\", \"euclidean\"],\n",
    "             #\"weights\": [\"uniform\", \"distance\"]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C_range = np.logspace(-2, 10, 2)\n",
    "gamma_range = np.logspace(-9, 3, 2)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#AHH this is the prob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e+10])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 0.01, 'gamma': 1e-09} with a score of 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   25.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# I had to do a LOT to get this to work! I switched around the logspace above for both c range and gamma.Having \n",
    "# two folds worked way better than having 125 fits. I also made the n_split smaller to have less fits  \n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "#rbf kernel\n",
    "gridRBF = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, cv=cv, verbose=True, n_jobs = -1)\n",
    "gridRBF.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (gridRBF.best_params_, gridRBF.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(1e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.84\n",
      "Accuracy on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "svmRBFgrid = SVC(kernel='rbf', C=.01, gamma=1e-09).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svmRBFgrid.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svmRBFgrid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.84      1.00      0.91       247\n",
      "          No       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test for SVC \n",
    "# Step 5: For each of your selected models\n",
    "\n",
    "#Run with the default parameters using cross-validation\n",
    "#Calculate precision, recall, and F1 for classification\n",
    "#Calculate r2, RMSE, and MAE for regression\n",
    "#Where possible adjust 2-3 parameters for each model\n",
    "#Report evaluation metrics for the best and worst-performing parameter settings\n",
    "# PROJECT ENDS WITH THIS CELL!\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, svmRBFgrid.predict(X_test),\n",
    "                             target_names=[\"Yes\", \"No\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "#dictionary of all values of k\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 25),\n",
    "             \"metric\": [\"manhattan\", \"minkowski\", \"euclidean\"],\n",
    "             \"weights\": [\"uniform\", \"distance\"]}\n",
    "# i want to see which parameters work best, so used above so I can tell which kind of metrics and weights \n",
    "\n",
    "#grid search on all values of k in dictionary\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know this won't work, but wanted to see the code to practice since it is not linear\n",
    "#everything after this is practice!! including logistic reg.\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(X_train, y_train))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "                                        \n",
    "\n",
    "log_reg = LogisticRegression(penalty=\"l1\", \n",
    "                                        dual=False, \n",
    "                                        tol=0.0001, \n",
    "                                        C=0.5, \n",
    "                                        fit_intercept=True, \n",
    "                                        intercept_scaling=1, \n",
    "                                        class_weight=None, \n",
    "                                        random_state=None, \n",
    "                                        solver='lbfgs', \n",
    "                                        max_iter=100, \n",
    "                                        multi_class='auto', \n",
    "                                        verbose=0, \n",
    "                                        warm_start=False, \n",
    "                                        n_jobs=None, l1_ratio=None)\n",
    "\n",
    "\n",
    "\n",
    "#knn2 = KNeighborsClassifier()\n",
    "\n",
    "#dictionary of all values of k\n",
    "#param_grid = {\"n_neighbors\": np.arange(1, 25),\n",
    " #            \"metric\": [\"manhattan\", \"minkowski\", \"euclidean\"],\n",
    "  #           \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "#grid search on all values of k in dictionary\n",
    "#knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "#knn_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_reg_gscv.best_params_\n",
    "#knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "#knn_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, marker in zip([0.001, 1, 100], ['o', '^', 'v']):\n",
    "    lr_l1 = LogisticRegression(C=C, solver='liblinear', penalty=\"l1\").fit(X_train, y_train)\n",
    "    print(\"Training accuracy of logreg with C={:.3f}: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_train, y_train)))\n",
    "    print(\"Test accuracy of logreg with C={:.3f}: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: For each of your selected models\n",
    "\n",
    "#Run with the default parameters using cross-validation\n",
    "#Calculate precision, recall, and F1 for classification\n",
    "#Calculate r2, RMSE, and MAE for regression\n",
    "#Where possible adjust 2-3 parameters for each model\n",
    "#Report evaluation metrics for the best and worst-performing parameter settings\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, logreg.predict(X_test),\n",
    "                             target_names=[\"Yes\", \"No\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
